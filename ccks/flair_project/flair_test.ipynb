{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-03 15:14:26,958 Reading data from C:\\Users\\a\\.flair\\datasets\\ud_english\n",
      "2020-10-03 15:14:26,969 Train: C:\\Users\\a\\.flair\\datasets\\ud_english\\en_ewt-ud-train.conllu\n",
      "2020-10-03 15:14:26,971 Dev: C:\\Users\\a\\.flair\\datasets\\ud_english\\en_ewt-ud-dev.conllu\n",
      "2020-10-03 15:14:26,973 Test: C:\\Users\\a\\.flair\\datasets\\ud_english\\en_ewt-ud-test.conllu\n",
      "Corpus: 1254 train + 200 dev + 208 test sentences\n",
      "Dictionary with 52 tags: <unk>, O, DT, NNP, IN, VBZ, JJ, ,, RB, MD, VB, VBG, NN, NNS, NNPS, ., VBD, VBN, CD, PRP, PRP$, TO, VBP, RBR, WRB, CC, JJR, HYPH, EX, -LRB-\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import UD_ENGLISH\n",
    "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings\n",
    "\n",
    "# 1. get the corpus\n",
    "corpus: Corpus = UD_ENGLISH().downsample(0.1)\n",
    "print(corpus)\n",
    "\n",
    "# 2. what tag do we want to predict?\n",
    "tag_type = 'pos'\n",
    "\n",
    "# 3. make the tag dictionary from the corpus\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "print(tag_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-03 15:24:02,279 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim.vectors.npy not found in cache, downloading to C:\\Users\\a\\AppData\\Local\\Temp\\tmpkymfyqa_\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████| 160000128/160000128 [02:40<00:00, 996462.21B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-03 15:26:44,840 copying C:\\Users\\a\\AppData\\Local\\Temp\\tmpkymfyqa_ to cache at C:\\Users\\a\\.flair\\embeddings\\glove.gensim.vectors.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-03 15:26:45,084 removing temp file C:\\Users\\a\\AppData\\Local\\Temp\\tmpkymfyqa_\n",
      "2020-10-03 15:26:47,123 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim not found in cache, downloading to C:\\Users\\a\\AppData\\Local\\Temp\\tmpoy9a74du\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████| 21494764/21494764 [00:17<00:00, 1212884.97B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-03 15:27:06,738 copying C:\\Users\\a\\AppData\\Local\\Temp\\tmpoy9a74du to cache at C:\\Users\\a\\.flair\\embeddings\\glove.gensim\n",
      "2020-10-03 15:27:06,795 removing temp file C:\\Users\\a\\AppData\\Local\\Temp\\tmpoy9a74du\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. initialize embeddings\n",
    "embedding_types = [\n",
    "\n",
    "    WordEmbeddings('en-glove'),\n",
    "    # comment in this line to use character embeddings\n",
    "    # CharacterEmbeddings(),\n",
    "\n",
    "    # comment in these lines to use flair embeddings\n",
    "    # FlairEmbeddings('news-forward'),\n",
    "    # FlairEmbeddings('news-backward'),\n",
    "]\n",
    "\n",
    "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-03 15:27:57,451 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-03 15:27:57,454 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings('en-glove')\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (rnn): LSTM(100, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=52, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2020-10-03 15:27:57,457 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-03 15:27:57,466 Corpus: \"Corpus: 1254 train + 200 dev + 208 test sentences\"\n",
      "2020-10-03 15:27:57,469 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-03 15:27:57,483 Parameters:\n",
      "2020-10-03 15:27:57,492  - learning_rate: \"0.1\"\n",
      "2020-10-03 15:27:57,497  - mini_batch_size: \"32\"\n",
      "2020-10-03 15:27:57,501  - patience: \"3\"\n",
      "2020-10-03 15:27:57,512  - anneal_factor: \"0.5\"\n",
      "2020-10-03 15:27:57,522  - max_epochs: \"150\"\n",
      "2020-10-03 15:27:57,526  - shuffle: \"True\"\n",
      "2020-10-03 15:27:57,528  - train_with_dev: \"False\"\n",
      "2020-10-03 15:27:57,531  - batch_growth_annealing: \"False\"\n",
      "2020-10-03 15:27:57,533 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-03 15:27:57,536 Model training base path: \"resources\\taggers\\example-pos\"\n",
      "2020-10-03 15:27:57,541 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-03 15:27:57,551 Device: cpu\n",
      "2020-10-03 15:27:57,555 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-03 15:27:57,559 Embeddings storage mode: cpu\n",
      "2020-10-03 15:27:57,565 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-03 15:28:01,107 epoch 1 - iter 4/40 - loss 69.94763184 - samples/sec: 36.81 - lr: 0.100000\n",
      "2020-10-03 15:28:04,661 epoch 1 - iter 8/40 - loss 63.90584326 - samples/sec: 36.35 - lr: 0.100000\n",
      "2020-10-03 15:28:07,839 epoch 1 - iter 12/40 - loss 61.15057850 - samples/sec: 40.63 - lr: 0.100000\n",
      "2020-10-03 15:28:11,160 epoch 1 - iter 16/40 - loss 60.58905530 - samples/sec: 39.20 - lr: 0.100000\n",
      "2020-10-03 15:28:14,230 epoch 1 - iter 20/40 - loss 59.22070789 - samples/sec: 42.06 - lr: 0.100000\n",
      "2020-10-03 15:28:18,324 epoch 1 - iter 24/40 - loss 58.46795432 - samples/sec: 31.49 - lr: 0.100000\n",
      "2020-10-03 15:28:21,436 epoch 1 - iter 28/40 - loss 56.67301655 - samples/sec: 41.46 - lr: 0.100000\n",
      "2020-10-03 15:28:24,741 epoch 1 - iter 32/40 - loss 55.82194197 - samples/sec: 39.33 - lr: 0.100000\n",
      "2020-10-03 15:28:27,980 epoch 1 - iter 36/40 - loss 55.33341641 - samples/sec: 39.87 - lr: 0.100000\n",
      "2020-10-03 15:28:31,520 epoch 1 - iter 40/40 - loss 54.82811003 - samples/sec: 36.37 - lr: 0.100000\n",
      "2020-10-03 15:28:31,521 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-03 15:28:31,523 EPOCH 1 done: loss 54.8281 - lr 0.1000000\n",
      "2020-10-03 15:28:32,813 DEV : loss 32.43396759033203 - score 0.2777\n",
      "2020-10-03 15:28:32,822 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-03 15:28:38,137 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-03 15:28:41,509 epoch 2 - iter 4/40 - loss 49.72091866 - samples/sec: 38.00 - lr: 0.100000\n",
      "2020-10-03 15:28:44,332 epoch 2 - iter 8/40 - loss 46.29890585 - samples/sec: 45.39 - lr: 0.100000\n",
      "2020-10-03 15:28:48,226 epoch 2 - iter 12/40 - loss 45.73498376 - samples/sec: 32.89 - lr: 0.100000\n",
      "2020-10-03 15:28:51,944 epoch 2 - iter 16/40 - loss 45.87788510 - samples/sec: 34.44 - lr: 0.100000\n",
      "2020-10-03 15:28:55,102 epoch 2 - iter 20/40 - loss 45.05110016 - samples/sec: 40.57 - lr: 0.100000\n",
      "2020-10-03 15:28:58,260 epoch 2 - iter 24/40 - loss 44.66826328 - samples/sec: 40.56 - lr: 0.100000\n",
      "2020-10-03 15:29:01,916 epoch 2 - iter 28/40 - loss 44.56934002 - samples/sec: 35.04 - lr: 0.100000\n",
      "2020-10-03 15:29:05,344 epoch 2 - iter 32/40 - loss 44.17849600 - samples/sec: 37.37 - lr: 0.100000\n",
      "2020-10-03 15:29:08,465 epoch 2 - iter 36/40 - loss 43.90849188 - samples/sec: 41.02 - lr: 0.100000\n",
      "2020-10-03 15:29:10,923 epoch 2 - iter 40/40 - loss 43.32518225 - samples/sec: 52.14 - lr: 0.100000\n",
      "2020-10-03 15:29:10,924 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-03 15:29:10,925 EPOCH 2 done: loss 43.3252 - lr 0.1000000\n",
      "2020-10-03 15:29:11,785 DEV : loss 24.744464874267578 - score 0.4083\n",
      "2020-10-03 15:29:11,798 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-03 15:29:15,847 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-03 15:29:19,123 epoch 3 - iter 4/40 - loss 38.50282955 - samples/sec: 39.13 - lr: 0.100000\n",
      "2020-10-03 15:29:22,523 epoch 3 - iter 8/40 - loss 38.62133694 - samples/sec: 37.67 - lr: 0.100000\n",
      "2020-10-03 15:29:25,273 epoch 3 - iter 12/40 - loss 37.54976622 - samples/sec: 46.58 - lr: 0.100000\n",
      "2020-10-03 15:29:28,800 epoch 3 - iter 16/40 - loss 37.41915035 - samples/sec: 36.30 - lr: 0.100000\n",
      "2020-10-03 15:29:32,045 epoch 3 - iter 20/40 - loss 36.70107851 - samples/sec: 39.47 - lr: 0.100000\n",
      "2020-10-03 15:29:35,022 epoch 3 - iter 24/40 - loss 36.23551957 - samples/sec: 43.05 - lr: 0.100000\n",
      "2020-10-03 15:29:39,265 epoch 3 - iter 28/40 - loss 36.40469101 - samples/sec: 30.17 - lr: 0.100000\n",
      "2020-10-03 15:29:42,220 epoch 3 - iter 32/40 - loss 36.20677578 - samples/sec: 43.36 - lr: 0.100000\n",
      "2020-10-03 15:29:45,567 epoch 3 - iter 36/40 - loss 35.88353348 - samples/sec: 38.28 - lr: 0.100000\n",
      "2020-10-03 15:29:47,900 epoch 3 - iter 40/40 - loss 35.36795416 - samples/sec: 54.91 - lr: 0.100000\n",
      "2020-10-03 15:29:47,901 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-03 15:29:47,902 EPOCH 3 done: loss 35.3680 - lr 0.1000000\n",
      "2020-10-03 15:29:48,778 DEV : loss 19.923006057739258 - score 0.5113\n",
      "2020-10-03 15:29:48,786 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-03 15:29:53,022 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-03 15:29:56,467 epoch 4 - iter 4/40 - loss 33.81538343 - samples/sec: 37.20 - lr: 0.100000\n",
      "2020-10-03 15:29:59,528 epoch 4 - iter 8/40 - loss 31.88748026 - samples/sec: 41.86 - lr: 0.100000\n",
      "2020-10-03 15:30:02,501 epoch 4 - iter 12/40 - loss 31.45071538 - samples/sec: 43.08 - lr: 0.100000\n",
      "2020-10-03 15:30:05,502 epoch 4 - iter 16/40 - loss 30.75235355 - samples/sec: 42.68 - lr: 0.100000\n",
      "2020-10-03 15:30:08,896 epoch 4 - iter 20/40 - loss 30.62232656 - samples/sec: 37.72 - lr: 0.100000\n",
      "2020-10-03 15:30:12,526 epoch 4 - iter 24/40 - loss 30.52052299 - samples/sec: 35.29 - lr: 0.100000\n",
      "2020-10-03 15:30:15,697 epoch 4 - iter 28/40 - loss 30.59724992 - samples/sec: 40.40 - lr: 0.100000\n",
      "2020-10-03 15:30:19,456 epoch 4 - iter 32/40 - loss 30.86018634 - samples/sec: 34.07 - lr: 0.100000\n",
      "2020-10-03 15:30:22,915 epoch 4 - iter 36/40 - loss 30.64645476 - samples/sec: 37.01 - lr: 0.100000\n",
      "2020-10-03 15:30:25,803 epoch 4 - iter 40/40 - loss 30.29469318 - samples/sec: 44.33 - lr: 0.100000\n",
      "2020-10-03 15:30:25,808 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-03 15:30:25,809 EPOCH 4 done: loss 30.2947 - lr 0.1000000\n",
      "2020-10-03 15:30:26,685 DEV : loss 16.924179077148438 - score 0.586\n",
      "2020-10-03 15:30:26,696 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-03 15:30:30,856 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-03 15:30:34,094 epoch 5 - iter 4/40 - loss 29.33578539 - samples/sec: 39.56 - lr: 0.100000\n",
      "2020-10-03 15:30:37,595 epoch 5 - iter 8/40 - loss 29.60935545 - samples/sec: 36.58 - lr: 0.100000\n",
      "2020-10-03 15:30:40,427 epoch 5 - iter 12/40 - loss 28.34058698 - samples/sec: 45.23 - lr: 0.100000\n",
      "2020-10-03 15:30:43,544 epoch 5 - iter 16/40 - loss 27.89489031 - samples/sec: 41.09 - lr: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-03 15:30:46,499 epoch 5 - iter 20/40 - loss 27.54028978 - samples/sec: 43.34 - lr: 0.100000\n",
      "2020-10-03 15:30:50,312 epoch 5 - iter 24/40 - loss 27.62365723 - samples/sec: 33.59 - lr: 0.100000\n",
      "2020-10-03 15:30:54,425 epoch 5 - iter 28/40 - loss 27.59787703 - samples/sec: 31.13 - lr: 0.100000\n",
      "2020-10-03 15:30:57,934 epoch 5 - iter 32/40 - loss 27.32355058 - samples/sec: 36.50 - lr: 0.100000\n",
      "2020-10-03 15:31:01,585 epoch 5 - iter 36/40 - loss 27.16571013 - samples/sec: 35.08 - lr: 0.100000\n",
      "2020-10-03 15:31:04,429 epoch 5 - iter 40/40 - loss 27.10799308 - samples/sec: 45.07 - lr: 0.100000\n",
      "2020-10-03 15:31:04,431 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-03 15:31:04,433 EPOCH 5 done: loss 27.1080 - lr 0.1000000\n",
      "2020-10-03 15:31:05,491 DEV : loss 15.066246032714844 - score 0.6348\n",
      "2020-10-03 15:31:05,509 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-03 15:31:10,236 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-03 15:31:13,693 epoch 6 - iter 4/40 - loss 26.24360704 - samples/sec: 37.10 - lr: 0.100000\n",
      "2020-10-03 15:31:16,858 epoch 6 - iter 8/40 - loss 24.39998603 - samples/sec: 40.48 - lr: 0.100000\n",
      "2020-10-03 15:31:19,921 epoch 6 - iter 12/40 - loss 24.09915876 - samples/sec: 41.81 - lr: 0.100000\n",
      "2020-10-03 15:31:23,476 epoch 6 - iter 16/40 - loss 23.64282054 - samples/sec: 36.04 - lr: 0.100000\n",
      "2020-10-03 15:31:27,206 epoch 6 - iter 20/40 - loss 23.83854623 - samples/sec: 34.34 - lr: 0.100000\n",
      "2020-10-03 15:31:31,195 epoch 6 - iter 24/40 - loss 24.60461263 - samples/sec: 32.10 - lr: 0.100000\n",
      "2020-10-03 15:31:35,743 epoch 6 - iter 28/40 - loss 24.61312352 - samples/sec: 28.17 - lr: 0.100000\n",
      "2020-10-03 15:31:41,511 epoch 6 - iter 32/40 - loss 24.93332401 - samples/sec: 22.22 - lr: 0.100000\n",
      "2020-10-03 15:31:45,908 epoch 6 - iter 36/40 - loss 24.93674800 - samples/sec: 29.12 - lr: 0.100000\n",
      "2020-10-03 15:31:48,897 epoch 6 - iter 40/40 - loss 24.39497461 - samples/sec: 42.85 - lr: 0.100000\n",
      "2020-10-03 15:31:48,899 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-03 15:31:48,901 EPOCH 6 done: loss 24.3950 - lr 0.1000000\n",
      "2020-10-03 15:31:50,831 DEV : loss 13.207682609558105 - score 0.6615\n",
      "2020-10-03 15:31:50,847 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-03 15:31:56,433 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-03 15:32:00,207 epoch 7 - iter 4/40 - loss 23.52782202 - samples/sec: 34.02 - lr: 0.100000\n",
      "2020-10-03 15:32:05,449 epoch 7 - iter 8/40 - loss 23.83442187 - samples/sec: 24.44 - lr: 0.100000\n",
      "2020-10-03 15:32:09,979 epoch 7 - iter 12/40 - loss 24.58355618 - samples/sec: 28.27 - lr: 0.100000\n",
      "2020-10-03 15:32:13,898 epoch 7 - iter 16/40 - loss 23.60381854 - samples/sec: 32.69 - lr: 0.100000\n",
      "2020-10-03 15:32:17,533 epoch 7 - iter 20/40 - loss 23.16958723 - samples/sec: 35.24 - lr: 0.100000\n",
      "2020-10-03 15:32:21,045 epoch 7 - iter 24/40 - loss 22.81592449 - samples/sec: 36.49 - lr: 0.100000\n",
      "2020-10-03 15:32:24,458 epoch 7 - iter 28/40 - loss 22.71294567 - samples/sec: 37.52 - lr: 0.100000\n",
      "2020-10-03 15:32:28,639 epoch 7 - iter 32/40 - loss 23.10026914 - samples/sec: 30.62 - lr: 0.100000\n",
      "2020-10-03 15:32:32,145 epoch 7 - iter 36/40 - loss 22.80510192 - samples/sec: 36.54 - lr: 0.100000\n",
      "2020-10-03 15:32:36,001 epoch 7 - iter 40/40 - loss 23.01183376 - samples/sec: 33.24 - lr: 0.100000\n",
      "2020-10-03 15:32:36,003 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-03 15:32:36,005 EPOCH 7 done: loss 23.0118 - lr 0.1000000\n",
      "2020-10-03 15:32:36,922 DEV : loss 11.98347282409668 - score 0.7064\n",
      "2020-10-03 15:32:36,935 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-03 15:32:41,175 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-03 15:32:44,125 epoch 8 - iter 4/40 - loss 19.99199438 - samples/sec: 43.43 - lr: 0.100000\n",
      "2020-10-03 15:32:46,961 epoch 8 - iter 8/40 - loss 19.61004877 - samples/sec: 45.15 - lr: 0.100000\n",
      "2020-10-03 15:32:50,984 epoch 8 - iter 12/40 - loss 21.07209587 - samples/sec: 31.85 - lr: 0.100000\n",
      "2020-10-03 15:32:54,429 epoch 8 - iter 16/40 - loss 21.22261059 - samples/sec: 37.17 - lr: 0.100000\n",
      "2020-10-03 15:32:58,142 epoch 8 - iter 20/40 - loss 21.50540676 - samples/sec: 34.49 - lr: 0.100000\n",
      "2020-10-03 15:33:01,270 epoch 8 - iter 24/40 - loss 21.60643053 - samples/sec: 41.00 - lr: 0.100000\n",
      "2020-10-03 15:33:04,907 epoch 8 - iter 28/40 - loss 21.19422804 - samples/sec: 35.22 - lr: 0.100000\n",
      "2020-10-03 15:33:08,124 epoch 8 - iter 32/40 - loss 21.23160708 - samples/sec: 39.81 - lr: 0.100000\n",
      "2020-10-03 15:33:11,906 epoch 8 - iter 36/40 - loss 21.24646939 - samples/sec: 33.87 - lr: 0.100000\n",
      "2020-10-03 15:33:14,847 epoch 8 - iter 40/40 - loss 21.41165576 - samples/sec: 43.55 - lr: 0.100000\n",
      "2020-10-03 15:33:14,848 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-03 15:33:14,849 EPOCH 8 done: loss 21.4117 - lr 0.1000000\n",
      "2020-10-03 15:33:15,749 DEV : loss 10.932875633239746 - score 0.7263\n",
      "2020-10-03 15:33:15,761 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-03 15:33:20,206 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-03 15:33:23,934 epoch 9 - iter 4/40 - loss 20.18182731 - samples/sec: 34.37 - lr: 0.100000\n",
      "2020-10-03 15:33:26,995 epoch 9 - iter 8/40 - loss 19.86952007 - samples/sec: 41.86 - lr: 0.100000\n",
      "2020-10-03 15:33:30,309 epoch 9 - iter 12/40 - loss 19.73810697 - samples/sec: 38.65 - lr: 0.100000\n",
      "2020-10-03 15:33:34,889 epoch 9 - iter 16/40 - loss 20.49354297 - samples/sec: 27.95 - lr: 0.100000\n",
      "2020-10-03 15:33:39,531 epoch 9 - iter 20/40 - loss 20.75476460 - samples/sec: 27.58 - lr: 0.100000\n",
      "2020-10-03 15:33:43,655 epoch 9 - iter 24/40 - loss 20.98130675 - samples/sec: 31.07 - lr: 0.100000\n",
      "2020-10-03 15:33:46,926 epoch 9 - iter 28/40 - loss 20.59803728 - samples/sec: 39.19 - lr: 0.100000\n",
      "2020-10-03 15:33:50,116 epoch 9 - iter 32/40 - loss 20.72753939 - samples/sec: 40.15 - lr: 0.100000\n",
      "2020-10-03 15:33:53,388 epoch 9 - iter 36/40 - loss 20.46847410 - samples/sec: 39.14 - lr: 0.100000\n",
      "2020-10-03 15:33:55,794 epoch 9 - iter 40/40 - loss 20.23649778 - samples/sec: 53.24 - lr: 0.100000\n",
      "2020-10-03 15:33:55,796 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-03 15:33:55,797 EPOCH 9 done: loss 20.2365 - lr 0.1000000\n",
      "2020-10-03 15:33:56,684 DEV : loss 10.49775218963623 - score 0.725\n",
      "2020-10-03 15:33:56,694 BAD EPOCHS (no improvement): 1\n",
      "2020-10-03 15:33:56,697 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-03 15:34:00,252 epoch 10 - iter 4/40 - loss 18.77539873 - samples/sec: 36.05 - lr: 0.100000\n",
      "2020-10-03 15:34:03,691 epoch 10 - iter 8/40 - loss 20.06322432 - samples/sec: 37.23 - lr: 0.100000\n",
      "2020-10-03 15:34:07,093 epoch 10 - iter 12/40 - loss 20.27170753 - samples/sec: 37.64 - lr: 0.100000\n",
      "2020-10-03 15:34:10,792 epoch 10 - iter 16/40 - loss 20.47882140 - samples/sec: 34.62 - lr: 0.100000\n",
      "2020-10-03 15:34:13,646 epoch 10 - iter 20/40 - loss 19.96577635 - samples/sec: 44.88 - lr: 0.100000\n",
      "2020-10-03 15:34:16,481 epoch 10 - iter 24/40 - loss 19.46949116 - samples/sec: 45.18 - lr: 0.100000\n",
      "2020-10-03 15:34:19,510 epoch 10 - iter 28/40 - loss 19.41875778 - samples/sec: 42.28 - lr: 0.100000\n",
      "2020-10-03 15:34:22,998 epoch 10 - iter 32/40 - loss 19.31564337 - samples/sec: 36.73 - lr: 0.100000\n",
      "2020-10-03 15:34:27,007 epoch 10 - iter 36/40 - loss 19.75144810 - samples/sec: 31.95 - lr: 0.100000\n",
      "2020-10-03 15:34:29,517 epoch 10 - iter 40/40 - loss 19.82119064 - samples/sec: 51.03 - lr: 0.100000\n",
      "2020-10-03 15:34:29,518 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-03 15:34:29,519 EPOCH 10 done: loss 19.8212 - lr 0.1000000\n",
      "2020-10-03 15:34:30,379 DEV : loss 9.92995548248291 - score 0.7468\n",
      "2020-10-03 15:34:30,390 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-03 15:34:34,416 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-03 15:34:37,187 epoch 11 - iter 4/40 - loss 18.04439163 - samples/sec: 46.24 - lr: 0.100000\n",
      "2020-10-03 15:34:40,698 epoch 11 - iter 8/40 - loss 19.08403063 - samples/sec: 36.49 - lr: 0.100000\n",
      "2020-10-03 15:34:43,391 epoch 11 - iter 12/40 - loss 18.79509735 - samples/sec: 47.56 - lr: 0.100000\n",
      "2020-10-03 15:34:46,739 epoch 11 - iter 16/40 - loss 19.03684533 - samples/sec: 38.25 - lr: 0.100000\n",
      "2020-10-03 15:34:50,589 epoch 11 - iter 20/40 - loss 19.58128214 - samples/sec: 33.28 - lr: 0.100000\n",
      "2020-10-03 15:34:53,470 epoch 11 - iter 24/40 - loss 19.10223238 - samples/sec: 44.47 - lr: 0.100000\n",
      "2020-10-03 15:34:56,742 epoch 11 - iter 28/40 - loss 19.21657528 - samples/sec: 39.15 - lr: 0.100000\n",
      "2020-10-03 15:35:00,001 epoch 11 - iter 32/40 - loss 19.14367366 - samples/sec: 39.29 - lr: 0.100000\n",
      "2020-10-03 15:35:03,432 epoch 11 - iter 36/40 - loss 18.97628379 - samples/sec: 37.33 - lr: 0.100000\n",
      "2020-10-03 15:35:05,968 epoch 11 - iter 40/40 - loss 19.01904180 - samples/sec: 50.53 - lr: 0.100000\n",
      "2020-10-03 15:35:05,971 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-03 15:35:05,973 EPOCH 11 done: loss 19.0190 - lr 0.1000000\n",
      "2020-10-03 15:35:06,864 DEV : loss 9.269055366516113 - score 0.7601\n",
      "2020-10-03 15:35:06,876 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-03 15:35:11,103 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-03 15:35:15,026 epoch 12 - iter 4/40 - loss 18.31719899 - samples/sec: 32.65 - lr: 0.100000\n",
      "2020-10-03 15:35:17,579 epoch 12 - iter 8/40 - loss 16.99155378 - samples/sec: 50.17 - lr: 0.100000\n",
      "2020-10-03 15:35:21,414 epoch 12 - iter 12/40 - loss 17.66894937 - samples/sec: 33.39 - lr: 0.100000\n",
      "2020-10-03 15:35:24,954 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-03 15:35:24,956 Exiting from training early.\n",
      "2020-10-03 15:35:24,958 Saving model ...\n",
      "2020-10-03 15:35:29,295 Done.\n",
      "2020-10-03 15:35:29,301 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-7a64c5db0313>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m               \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m               \u001b[0mmini_batch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m               max_epochs=150)\n\u001b[0m",
      "\u001b[1;32mc:\\users\\a\\anaconda3\\envs\\pytorch\\lib\\site-packages\\flair\\trainers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, base_path, learning_rate, mini_batch_size, mini_batch_chunk_size, max_epochs, scheduler, cycle_momentum, anneal_factor, patience, initial_extra_patience, min_learning_rate, train_with_dev, monitor_train, monitor_test, embeddings_storage_mode, checkpoint, save_final_model, anneal_with_restarts, anneal_with_prestarts, batch_growth_annealing, shuffle, param_selection_mode, write_weights, num_workers, sampler, use_amp, amp_opt_level, eval_on_train_fraction, eval_on_train_shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    607\u001b[0m         \u001b[1;31m# test best model if test data is present\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 609\u001b[1;33m             \u001b[0mfinal_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinal_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_batch_chunk_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    610\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m             \u001b[0mfinal_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\a\\anaconda3\\envs\\pytorch\\lib\\site-packages\\flair\\trainers\\trainer.py\u001b[0m in \u001b[0;36mfinal_test\u001b[1;34m(self, base_path, eval_mini_batch_size, num_workers)\u001b[0m\n\u001b[0;32m    642\u001b[0m             \u001b[0mbase_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m         \u001b[0mlog_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m         \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Testing using best model ...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\a\\anaconda3\\envs\\pytorch\\lib\\site-packages\\flair\\training_utils.py\u001b[0m in \u001b[0;36mlog_line\u001b[1;34m(log)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlog_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m     \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\a\\anaconda3\\envs\\pytorch\\lib\\logging\\__init__.py\u001b[0m in \u001b[0;36minfo\u001b[1;34m(self, msg, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1306\u001b[0m         \"\"\"\n\u001b[0;32m   1307\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misEnabledFor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mINFO\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1308\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mINFO\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1310\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\a\\anaconda3\\envs\\pytorch\\lib\\logging\\__init__.py\u001b[0m in \u001b[0;36m_log\u001b[1;34m(self, level, msg, args, exc_info, extra, stack_info)\u001b[0m\n\u001b[0;32m   1442\u001b[0m         record = self.makeRecord(self.name, level, fn, lno, msg, args,\n\u001b[0;32m   1443\u001b[0m                                  exc_info, func, extra, sinfo)\n\u001b[1;32m-> 1444\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1446\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\a\\anaconda3\\envs\\pytorch\\lib\\logging\\__init__.py\u001b[0m in \u001b[0;36mhandle\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m   1452\u001b[0m         \"\"\"\n\u001b[0;32m   1453\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisabled\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1454\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallHandlers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1456\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0maddHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\a\\anaconda3\\envs\\pytorch\\lib\\logging\\__init__.py\u001b[0m in \u001b[0;36mcallHandlers\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m   1514\u001b[0m                 \u001b[0mfound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfound\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1515\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mrecord\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlevelno\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mhdlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1516\u001b[1;33m                     \u001b[0mhdlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1517\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1518\u001b[0m                 \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m    \u001b[1;31m#break out\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\a\\anaconda3\\envs\\pytorch\\lib\\logging\\__init__.py\u001b[0m in \u001b[0;36mhandle\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m    863\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 865\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0memit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    866\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\a\\anaconda3\\envs\\pytorch\\lib\\logging\\__init__.py\u001b[0m in \u001b[0;36memit\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m    996\u001b[0m             \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    997\u001b[0m             \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 998\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    999\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1000\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandleError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\a\\anaconda3\\envs\\pytorch\\lib\\logging\\__init__.py\u001b[0m in \u001b[0;36mflush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    976\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"flush\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 978\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    979\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\a\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mflush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    348\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mimport_lock_held\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m                 \u001b[0mevt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEvent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m                 \u001b[1;31m# and give a timeout to avoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\a\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    203\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[1;31m# wake event thread (message content is ignored)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\a\\anaconda3\\envs\\pytorch\\lib\\site-packages\\zmq\\sugar\\socket.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    414\u001b[0m                                  copy_threshold=self.copy_threshold)\n\u001b[0;32m    415\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mzmq\\backend\\cython\\socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq\\backend\\cython\\socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq\\backend\\cython\\socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\users\\a\\anaconda3\\envs\\pytorch\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
    "\n",
    "# 5. initialize sequence tagger\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
    "                                        embeddings=embeddings,\n",
    "                                        tag_dictionary=tag_dictionary,\n",
    "                                        tag_type=tag_type,\n",
    "                                        use_crf=True)\n",
    "\n",
    "# 6. initialize trainer\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "# 7. start training\n",
    "trainer.train('resources/taggers/example-pos',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              max_epochs=150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
